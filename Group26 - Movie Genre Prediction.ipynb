{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"E:/Semester 6/IE 406 - 4.0 - Machine Learning/Project/codes/train.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image pre-processing\n",
    "## since image size is different from all images we need to preprocess them and assign a fix width and height to each of them\n",
    "Here, we are resizing each image into dimension of 150 X 101 X 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=100\n",
    "img_height=100\n",
    "\n",
    "x=[]\n",
    "\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "\n",
    "  path = 'E:/Semester 6/IE 406 - 4.0 - Machine Learning/Project/codes/Images/' +data['Id'][i] + '.jpg'\n",
    "  pic = image.load_img(path,target_size=(img_height, img_width, 3)) \n",
    "  pic = image.img_to_array(pic)\n",
    "  pic = pic/255.0\n",
    "  x.append(pic)\n",
    "\n",
    "X=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[11])\n",
    "print(\"Genre:\", data['Genre'][11])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data.drop(['Id','Genre'],axis=1)\n",
    "y=y.values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5000\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:n], y[:n], test_size = 0.15, random_state = 0)\n",
    "print(\"Image size =\", X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our custom CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape = X_train[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2, 2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(25, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(X_train, y_train, epochs=10, validation_data = (X_val, y_val))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learningCurve(history,epoch):\n",
    "\n",
    "    epoch_range=range(1,epoch+1)\n",
    "    \n",
    "    plt.plot(epoch_range,history.history['accuracy'])\n",
    "    plt.plot(epoch_range,history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Val'],loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.plot(epoch_range,history.history['loss'])\n",
    "    plt.plot(epoch_range,history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Val'],loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learningCurve(history,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "X_test = X[n:n + n_test]\n",
    "y_test = y[n:n + n_test]\n",
    "\n",
    "pred = model.predict(np.array(X_test))\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_test, pred):\n",
    "    value = 0\n",
    "\n",
    "    for i in range(0, len(pred)):\n",
    "        first3_index = np.argsort(pred[i])[-3:]\n",
    "        correct = np.where(y_test[i] == 1)[0]\n",
    "        flag=1\n",
    "\n",
    "        for j in first3_index:\n",
    "            if j in correct:\n",
    "                if flag==1:\n",
    "                    value += 1\n",
    "                    flag=0\n",
    "\n",
    "    acc = value/len(pred)\n",
    "\n",
    "    print(\"Accuracy =\", acc*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing image outside from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(path):\n",
    "    \n",
    "    img_width=100\n",
    "    img_height=100\n",
    "\n",
    "    pic=image.load_img(path, target_size=(img_height, img_width, 3)) \n",
    "    plt.imshow(pic)\n",
    "\n",
    "    pic=image.img_to_array(pic)\n",
    "    pic=pic/255.0\n",
    "    pic=pic.reshape(1, img_height, img_width, 3)\n",
    "\n",
    "    classes=data.columns[2:]\n",
    "    y_prob=model.predict(pic)\n",
    "    top_3= np.argsort(y_prob[0])[-3:]\n",
    "\n",
    "    print(\"Predicted Genre are as follows:\")\n",
    "    print()\n",
    "\n",
    "    for i in range(3):\n",
    "        print(\"     \", classes[top_3[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre('E:/Semester 6/IE 406 - 4.0 - Machine Learning/Project/codes/extra/phir_hera_pheri.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre('E:/Semester 6/IE 406 - 4.0 - Machine Learning/Project/codes/extra/toystoryposter.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranfer learning\n",
    "### We even tested on cover of books; however, since features of book covers are different than movie posters, it is not always right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre('E:/Semester 6/IE 406 - 4.0 - Machine Learning/Project/codes/extra/gone_girl.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_genre('E:/Semester 6/IE 406 - 4.0 - Machine Learning/Project/codes/extra/the_fault_in_our_stars.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END of CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bita484497671ff47bbaa9dedd6d6cd5f4d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}